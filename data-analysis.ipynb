{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "from sqgbrwa.utils import *\n",
    "from sqgbrwa.pulse_envelopes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure font sizes are large enough to read\n",
    "poster_sizes = [24, 26, 28]\n",
    "presentation_sizes = [16, 18, 20]\n",
    "SMALL_SIZE = presentation_sizes[0]\n",
    "MEDIUM_SIZE = presentation_sizes[1]\n",
    "BIGGER_SIZE = presentation_sizes[2]\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"U:/AndersenLab/quantify-data/\" ## This should refer to the folder that contains the data\n",
    "gates_per_clifford = 1.875\n",
    "figure_data = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual ZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(120e-9, 50_000e-9, 500e-9)\n",
    "\n",
    "def fun(x, a, b, tau, w, phi):\n",
    "    return a + b*np.exp(-x/tau)*np.sin(w*x + phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = [\n",
    "    get_data_folders(base_dir+\"20241128/\", start=142923, stop=142923)[0],\n",
    "    get_data_folders(base_dir+\"20241128/\", start=143938, stop=143938)[0],\n",
    "    get_data_folders(base_dir+\"20241128/\", start=144952, stop=144952)[0],\n",
    "    get_data_folders(base_dir+\"20241128/\", start=151023, stop=151023)[0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_T2 = np.zeros(4)\n",
    "results_std = np.zeros(4)\n",
    "\n",
    "for i,data_folder in enumerate(data_folders):\n",
    "    # Get 0 counts\n",
    "    with h5py.File(data_folder+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0 = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "    # Fit\n",
    "    x0 = [np.mean(counts_0), np.max(counts_0)-np.min(counts_0), 15e-6, 2*np.pi*0.07e6, np.pi]\n",
    "    popt,pcov = curve_fit(fun, times, counts_0, p0=x0)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "\n",
    "    results_T2[i] = popt[3]\n",
    "    results_std[i] = perr[3]\n",
    "\n",
    "    # Make figure\n",
    "    fig,ax = fig_prepare(r\"Times ($\\mu$s)\", \"0 Probability\")\n",
    "    ax.plot(times*1e6, fun(times, *popt), linestyle=\"-\",color=colors[\"red\"],linewidth=2)\n",
    "    ax.plot(times*1e6, counts_0, linestyle=\"\",color=colors[\"blue\"],marker=\".\",markersize=8)\n",
    "    fig.tight_layout()\n",
    "\n",
    "T2 = (results_T2[0] + results_T2[3] - results_T2[1] - results_T2[2]) / 2\n",
    "err = np.sum(results_std) / 2\n",
    "print(rf\"T2 = {T2*1e-3} \\pm {err*1e-3} kHz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1/T2E\n",
    "Here, I collect many T1/T2E measurements to get an average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders_T1 = [\n",
    "    (\"20241213/\", 220351),\n",
    "    (\"20241213/\", 235343),\n",
    "    (\"20241214/\",  15206),\n",
    "    (\"20241214/\",  35505),\n",
    "    (\"20241214/\",  60224),\n",
    "    (\"20241213/\", 121612),\n",
    "    (\"20241213/\", 140814),\n",
    "    (\"20241213/\", 160251),\n",
    "    (\"20241213/\", 180245),\n",
    "    (\"20241213/\", 200623),\n",
    "    (\"20241220/\", 120811),\n",
    "    (\"20241220/\", 154351),\n",
    "    (\"20241220/\", 192253),\n",
    "    (\"20241220/\", 230514),\n",
    "    (\"20241221/\",  23617),\n",
    "    (\"20241219/\", 163221),\n",
    "    (\"20241219/\", 203333),\n",
    "    (\"20241220/\",   3145),\n",
    "    (\"20241220/\",  42120),\n",
    "    (\"20241220/\",  83134),\n",
    "]\n",
    "\n",
    "data_folders_T2E = [\n",
    "    (\"20241213/\", 220658),\n",
    "    (\"20241213/\", 235652),\n",
    "    (\"20241214/\",  15524),\n",
    "    (\"20241214/\",  35824),\n",
    "    (\"20241214/\",  60533),\n",
    "    (\"20241213/\", 121912),\n",
    "    (\"20241213/\", 141116),\n",
    "    (\"20241213/\", 160554),\n",
    "    (\"20241213/\", 180552),\n",
    "    (\"20241213/\", 200939),\n",
    "    (\"20241220/\", 121246),\n",
    "    (\"20241220/\", 154833),\n",
    "    (\"20241220/\", 192732),\n",
    "    (\"20241220/\", 230957),\n",
    "    (\"20241221/\",  24050),\n",
    "    (\"20241219/\", 163650),\n",
    "    (\"20241219/\", 203814),\n",
    "    (\"20241220/\",   3615),\n",
    "    (\"20241220/\",  42552),\n",
    "    (\"20241220/\",  83608),\n",
    "]\n",
    "\n",
    "data_folders_T1 = [get_data_folders(base_dir+x[0], start=x[1], stop=x[1])[0] for x in data_folders_T1]\n",
    "data_folders_T2E = [get_data_folders(base_dir+x[0], start=x[1], stop=x[1])[0] for x in data_folders_T2E]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_T1  = []\n",
    "results_T2E = []\n",
    "\n",
    "times_T1  = np.arange(200e-9, 500e-6, 10e-6)\n",
    "times_T2E = np.arange(200e-9, 150e-6, 5e-6)\n",
    "\n",
    "def fun(x,a,b,c):\n",
    "    return a*np.exp(-x/b) + c\n",
    "\n",
    "for i in range(len(data_folders_T1)):\n",
    "    data_folder_T1 = data_folders_T1[i]\n",
    "    data_folder_T2E = data_folders_T2E[i]\n",
    "\n",
    "    # Get counts\n",
    "    with h5py.File(data_folder_T1+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0_T1 = np.array(list(f[\"counts_0\"]))\n",
    "    with h5py.File(data_folder_T2E+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0_T2E = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "    x0_T1  = [counts_0_T1[0]-counts_0_T1[-1], 70e-6, counts_0_T1[-1]]\n",
    "    x0_T2E = [-counts_0_T2E[-1], 35e-6, counts_0_T2E[-1]]\n",
    "\n",
    "    popt_T1, _ = curve_fit(fun, times_T1,  counts_0_T1,  p0=x0_T1)\n",
    "    popt_T2E,_ = curve_fit(fun, times_T2E, counts_0_T2E, p0=x0_T2E)\n",
    "\n",
    "    results_T1.append(popt_T1[1])\n",
    "    results_T2E.append(popt_T2E[1])\n",
    "\n",
    "    if i==0:\n",
    "        fig,ax = fig_prepare(\"Times\", \"0 Counts\")\n",
    "        ax.plot(times_T1*1e6, fun(times_T1, *popt_T1), color=\"#333\", linewidth=2)\n",
    "        ax.plot(times_T1*1e6, counts_0_T1, linestyle=\"\", marker=\".\", color=colors[\"blue\"])\n",
    "\n",
    "        fig,ax = fig_prepare(\"Times\", \"0 Counts\")\n",
    "        ax.plot(times_T2E*1e6, fun(times_T2E, *popt_T2E), color=\"#333\", linewidth=2)\n",
    "        ax.plot(times_T2E*1e6, counts_0_T2E, linestyle=\"\", marker=\".\", color=colors[\"blue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_T1), np.mean(results_T2E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocol 1 & 2 & 3 vs coherence limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs = np.array([40, 33.333, 26.666, 20, 13.333])\n",
    "\n",
    "# Fit exponential\n",
    "def fun(m, A0, p, B0):\n",
    "    return A0*p**m + B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RB and IRB data\n",
    "data_folders = [\n",
    "    ## Protocol 1\n",
    "    # 40 ns\n",
    "    (\"20241227/\", 210514),\n",
    "    (\"20241227/\", 222818),\n",
    "    # 33.333 ns\n",
    "    (\"20241227/\", 120552),\n",
    "    (\"20241227/\", 132538),\n",
    "    # 26.666 ns\n",
    "    (\"20241226/\", 222247),\n",
    "    (\"20241226/\", 233953),\n",
    "    # 20 ns\n",
    "    (\"20241226/\", 140432),\n",
    "    (\"20241226/\", 151616),\n",
    "    # 13.333 ns\n",
    "    (\"20241225/\", 173309),\n",
    "    (\"20241225/\", 184627),\n",
    "\n",
    "    ## Protocol 2\n",
    "    # 40 ns\n",
    "    (\"20241224/\", 174017),\n",
    "    (\"20241224/\", 201931),\n",
    "    # 33.333 ns\n",
    "    (\"20241224/\", 92909),\n",
    "    (\"20241224/\", 112754),\n",
    "    # 26.666 ns\n",
    "    (\"20241223/\", 163451),\n",
    "    (\"20241223/\", 183210),\n",
    "    # 20 ns\n",
    "    (\"20241222/\", 160044),\n",
    "    (\"20241222/\", 175215),\n",
    "    # 13.333 ns\n",
    "    (\"20241225/\", 81301),\n",
    "    (\"20241225/\", 95119),\n",
    "\n",
    "    ## Protocol 2\n",
    "    # # 40 ns\n",
    "    # (\"20241228/\", 213255),\n",
    "    # (\"20241228/\", 141354),\n",
    "    # # 33.333 ns\n",
    "    # (\"20241229/\", 142203),\n",
    "    # (\"20241229/\", 154313),\n",
    "    # # 26.666 ns\n",
    "    # (\"20241229/\", 221613),\n",
    "    # (\"20241229/\", 233637),\n",
    "    # # 20 ns\n",
    "    # (\"20241230/\", 120216),\n",
    "    # (\"20241230/\", 132325),\n",
    "    # # 13.333 ns\n",
    "    # (\"20241230/\", 220159),\n",
    "    # (\"20241230/\", 231843),\n",
    "\n",
    "    ## Protocol 3\n",
    "    # 40 ns\n",
    "    (\"20250109/\", 200912),\n",
    "    (\"20250109/\", 235813),\n",
    "    # 33.333 ns\n",
    "    (\"20250109/\", 94247),\n",
    "    (\"20250109/\", 115049),\n",
    "    # 26.666 ns\n",
    "    (\"20250108/\", 231250),\n",
    "    (\"20250109/\", 12923),\n",
    "    # 20 ns\n",
    "    (\"20250108/\", 113442),\n",
    "    (\"20250108/\", 134251),\n",
    "    # 13.333 ns\n",
    "    (\"20250110/\", 112016),\n",
    "    (\"20250110/\", 130553),\n",
    "\n",
    "    ## Protocol 4\n",
    "    # 13.333 ns\n",
    "    (\"20250114/\", 215941),\n",
    "    (\"20250110/\", 130553),\n",
    "]\n",
    "\n",
    "data_folders = [get_data_folders(base_dir+x[0], start=x[1], stop=x[1])[0] for x in data_folders]\n",
    "\n",
    "Mmax = [\n",
    "    ## Protocol 1\n",
    "    (500, 2000),                # 40\n",
    "    (400, 2000),                # 33.333\n",
    "    (300, 2000),                # 26.666\n",
    "    (200, 2000),                # 20\n",
    "    (200, 2000),                # 13.333\n",
    "\n",
    "    ## Protocol 2\n",
    "    (2000, 2000),                # 40\n",
    "    (2000, 2000),                # 33.333\n",
    "    (2000, 2000),                # 26.666\n",
    "    (2000, 2000),                # 20\n",
    "    (1250, 1250),                # 13.333\n",
    "\n",
    "    ## Protocol 2\n",
    "    # (500, 500),                # 40\n",
    "    # (500, 500),                # 33.333\n",
    "    # (500, 500),                # 26.666\n",
    "    # (500, 500),                # 20\n",
    "    # (500, 500),                # 13.333\n",
    "\n",
    "    ## Protocol 3\n",
    "    (2000, 2000),                # 40\n",
    "    (2000, 2000),                # 33.333\n",
    "    (2000, 2000),                # 26.666\n",
    "    (2000, 2000),                # 20\n",
    "    (1250, 1250),                # 13.333\n",
    "\n",
    "    # Protocol 4\n",
    "    (2000, 2000)\n",
    "]\n",
    "K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_errors = np.zeros(32)\n",
    "results_stds   = np.zeros(32)\n",
    "\n",
    "weights = np.arange(12)\n",
    "M = (np.array([sum(weights[:(i+1)])/np.sum(weights) for i in range(12)]) * 2000).astype(int)\n",
    "M[0] = 1\n",
    "figure_data[1] = dict(\n",
    "    x0 = np.copy(M),\n",
    "    y0 = np.zeros((len(data_folders)//2, 3)),\n",
    "    y1 = np.zeros((len(data_folders)//2, 12))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    if isinstance(Mmax[i], tuple):\n",
    "        Mmax_rb = Mmax[i][0]\n",
    "        Mmax_prb = Mmax[i][1]\n",
    "    else:\n",
    "        Mmax_rb = Mmax_prb = Mmax[i]\n",
    "    weights = np.arange(12)\n",
    "    M_rb = (np.array([sum(weights[:(i+1)])/np.sum(weights) for i in range(12)]) * Mmax_rb).astype(int)\n",
    "    M_rb[0] = 1\n",
    "    M_prb = (np.array([sum(weights[:(i+1)])/np.sum(weights) for i in range(12)]) * Mmax_prb).astype(int)\n",
    "    M_prb[0] = 1\n",
    "\n",
    "    # Get 0 counts\n",
    "    with h5py.File(data_folders[2*i]+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0_rb = np.array(list(f[\"counts_0\"]))\n",
    "    with h5py.File(data_folders[2*i+1]+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0_prb = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "    outputs_z = counts_0_prb[0::3].reshape((len(M_prb),K))\n",
    "    outputs_x = counts_0_prb[1::3].reshape((len(M_prb),K))\n",
    "    outputs_y = counts_0_prb[2::3].reshape((len(M_prb),K))\n",
    "\n",
    "    # Convert counts to expectations values\n",
    "    outputs_z = -(2*outputs_z - 1)\n",
    "    outputs_x = -(2*outputs_x - 1)\n",
    "    outputs_y = -(2*outputs_y - 1)\n",
    "\n",
    "    results_rb  = counts_0_rb.reshape((len(M_rb),K))\n",
    "    results_prb = np.sqrt(outputs_z**2 + outputs_x**2 + outputs_y**2)\n",
    "\n",
    "    # Average 0 counts and fit\n",
    "    outputs_mean_rb  = np.mean(results_rb, axis=1)\n",
    "    outputs_mean_prb = np.mean(results_prb, axis=1)\n",
    "    figure_data[1][\"y1\"][i,:] = outputs_mean_rb\n",
    "\n",
    "    # Fit exponential\n",
    "    popt_rb,pcov_rb   = curve_fit(fun, M_rb, outputs_mean_rb,  p0=[0.25,0.999,0.5])\n",
    "    popt_prb,pcov_prb = curve_fit(fun, M_prb, outputs_mean_prb, p0=[0.25,0.999,0.5])\n",
    "    perr_rb = np.sqrt(np.diag(pcov_rb))\n",
    "    perr_prb = np.sqrt(np.diag(pcov_prb))\n",
    "    figure_data[1][\"y0\"][i,:] = popt_rb\n",
    "\n",
    "    # Extract error\n",
    "    results_errors[2*i] = (1-popt_rb[1])/2/gates_per_clifford\n",
    "    results_errors[2*i+1] = (1-popt_prb[1])/2/gates_per_clifford\n",
    "    results_stds[2*i] = (perr_rb[1])/2/gates_per_clifford\n",
    "    results_stds[2*i+1] = (perr_prb[1])/2/gates_per_clifford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = 1e-9 * np.linspace(np.min(tgs), np.max(tgs), 101)\n",
    "coherence_limit = 0.5 + 1/6 * np.exp(-xx/75e-6) + 1/3*np.exp(-xx/37e-6)\n",
    "coherence_limit = (1-coherence_limit)\n",
    "\n",
    "results_purity_p3 = results_errors[21:31:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#f1a226\", \"#298c8c\", \"#8C3C29\"]\n",
    "\n",
    "fig,ax = fig_prepare(r\"$t_g$ (ns)\", \"Error\", yscale=\"log\")\n",
    "# ax.plot(xx*1e9, coherence_limit, color=\"#666\")\n",
    "(_, caps1, _) = ax.errorbar(tgs, results_errors[:10:2], yerr=results_stds[:10:2], linestyle=\"\", marker=\"^\", markersize=9, capsize=6, linewidth=2, color=color_list[0], label=\"Protocol 1\")\n",
    "(_, caps2, _) = ax.errorbar(tgs, results_errors[10:20:2], yerr=results_stds[10:20:2], linestyle=\"\", marker=\">\", markersize=9, capsize=6, linewidth=2, color=color_list[1], label=\"Protocol 2\")\n",
    "(_, caps3, _) = ax.errorbar(tgs, results_errors[20:30:2], yerr=results_stds[20:30:2], linestyle=\"\", marker=\"v\", markersize=9, capsize=6, linewidth=2, color=color_list[2], label=\"Protocol 3\")\n",
    "ax.errorbar(tgs[-1], results_errors[-2], yerr=results_stds[-2], linestyle=\"\", marker=\"<\", markersize=9, capsize=6, linewidth=2, color=\"#8C2983\", label=\"Protocol 4\")\n",
    "ax.plot(xx*1e9, coherence_limit, linewidth=2, color=\"#333\", label=\"Coherence limit\")\n",
    "ax.plot(tgs, results_purity_p3, linewidth=2, color=\"#333\", linestyle=\"--\", label=\"Incoh. error\")\n",
    "\n",
    "for cap in caps1+caps2+caps3:\n",
    "    cap.set_markeredgewidth(1.5)\n",
    "\n",
    "ax.set_xticks(ticks=np.flip(tgs), \n",
    "              labels=[13.3, 20, 26.7, 33.3, 40])\n",
    "ax.legend(loc=[1.02,0.32])\n",
    "ax.set_yticks([1e-4,1e-3,1e-2,1e-1])\n",
    "fig.set_size_inches(9,4)\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig.savefig(\"protocol123-rb-prb.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_data[0] = dict(\n",
    "    x0=np.copy(tgs),\n",
    "    y0=np.copy(results_errors),\n",
    "    y1=np.copy(results_stds),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sim data\n",
    "extended_data1 = load_dataset(\"20250124-171107\", folder_name=\"extended-data\", json_fname=\"extended_data\")\n",
    "extended_data2 = load_dataset(\"20250123-194712\", folder_name=\"extended-data\", json_fname=\"extended_data\")\n",
    "extended_data3 = load_dataset(\"20250126-133937\", folder_name=\"extended-data\", json_fname=\"extended_data\")\n",
    "extended_data = dict()\n",
    "extended_data[\"error_budget\"] = extended_data1[\"error_budget\"] | extended_data2[\"error_budget\"] | extended_data3[\"error_budget\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs = extended_data[\"error_budget\"][\"x0\"]\n",
    "\n",
    "results_p1_tls_pi_error  = 1 - extended_data[\"error_budget\"][\"y0\"]\n",
    "results_p1_tls_pi2_error = 1 - extended_data[\"error_budget\"][\"y1\"]\n",
    "results_p1_4ls_pi_error  = 1 - extended_data[\"error_budget\"][\"y4\"]\n",
    "results_p1_4ls_pi2_error = 1 - extended_data[\"error_budget\"][\"y5\"]\n",
    "results_p2_tls_pi_error  = 1 - np.mean(extended_data[\"error_budget\"][\"y8\"], axis=1)\n",
    "results_p2_tls_pi2_error = 1 - np.mean(extended_data[\"error_budget\"][\"y9\"], axis=1)\n",
    "results_p2_4ls_pi_error  = 1 - np.mean(extended_data[\"error_budget\"][\"y14\"], axis=1)\n",
    "results_p2_4ls_pi2_error = 1 - np.mean(extended_data[\"error_budget\"][\"y15\"], axis=1)\n",
    "results_p3_4ls_pi_error  = 1 - np.mean(extended_data[\"error_budget\"][\"y22\"], axis=1)\n",
    "results_p3_4ls_pi2_error = 1 - np.mean(extended_data[\"error_budget\"][\"y23\"], axis=1)\n",
    "results_p4_tls_pi_error  = 1 - np.mean(extended_data[\"error_budget\"][\"y32\"], axis=1)\n",
    "results_p4_tls_pi2_error = 1 - np.mean(extended_data[\"error_budget\"][\"y33\"], axis=1)\n",
    "results_p4_4ls_pi_error  = 1 - np.mean(extended_data[\"error_budget\"][\"y40\"], axis=1)\n",
    "results_p4_4ls_pi2_error = 1 - np.mean(extended_data[\"error_budget\"][\"y41\"], axis=1)\n",
    "\n",
    "leakage_p1_pi  = np.mean(extended_data[\"error_budget\"][\"y30\"], axis=1)\n",
    "leakage_p1_pi2 = np.mean(extended_data[\"error_budget\"][\"y31\"], axis=1)\n",
    "leakage_p2_pi  = np.mean(extended_data[\"error_budget\"][\"y20\"], axis=1)\n",
    "leakage_p2_pi2 = np.mean(extended_data[\"error_budget\"][\"y21\"], axis=1)\n",
    "leakage_p3_pi  = np.mean(extended_data[\"error_budget\"][\"y28\"], axis=1)\n",
    "leakage_p3_pi2 = np.mean(extended_data[\"error_budget\"][\"y29\"], axis=1)\n",
    "leakage_p4_pi  = np.mean(extended_data[\"error_budget\"][\"y50\"], axis=1)\n",
    "leakage_p4_pi2 = np.mean(extended_data[\"error_budget\"][\"y51\"], axis=1)\n",
    "\n",
    "coherence_limit = 0.5 + 1/6 * np.exp(-xx/75e-6) + 1/3*np.exp(-xx/37e-6)\n",
    "coherence_limit = (1-coherence_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_p1_measured = np.flip(results_errors[:10:2])\n",
    "errors_p2_measured = np.flip(results_errors[10:20:2])\n",
    "errors_p3_measured = np.flip(results_errors[20:30:2])\n",
    "errors_p4_measured = np.zeros(len(tgs))\n",
    "errors_p4_measured[0] = results_errors[-2]\n",
    "\n",
    "prb_p1_measured = np.flip(results_errors[1:11:2])\n",
    "prb_p2_measured = np.flip(results_errors[11:21:2])\n",
    "prb_p3_measured = np.flip(results_errors[21:31:2])\n",
    "prb_p4_measured = np.zeros(len(tgs))\n",
    "prb_p4_measured[0] = results_errors[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 error budget\n",
    "error_coherent_p1_pi = results_p1_4ls_pi_error\n",
    "error_coherent_p1_pi2 = results_p1_4ls_pi2_error\n",
    "error_higher_levels_p1_pi = error_coherent_p1_pi - results_p1_tls_pi_error\n",
    "error_higher_levels_p1_pi2 = error_coherent_p1_pi2 - results_p1_tls_pi2_error\n",
    "\n",
    "# p2 error budget\n",
    "error_coherent_p2_pi = results_p2_4ls_pi_error\n",
    "error_coherent_p2_pi2 = results_p2_4ls_pi2_error\n",
    "error_higher_levels_p2_pi = error_coherent_p2_pi - results_p2_tls_pi_error\n",
    "error_higher_levels_p2_pi2 = error_coherent_p2_pi2 - results_p2_tls_pi2_error\n",
    "\n",
    "# p3 error budget\n",
    "error_coherent_p3_pi = results_p3_4ls_pi_error\n",
    "error_coherent_p3_pi2 = results_p3_4ls_pi2_error\n",
    "error_higher_levels_p3_pi = error_coherent_p3_pi - results_p2_tls_pi_error\n",
    "error_higher_levels_p3_pi2 = error_coherent_p3_pi2 - results_p2_tls_pi2_error\n",
    "\n",
    "# p4 error budget\n",
    "error_coherent_p4_pi = results_p4_4ls_pi_error\n",
    "error_coherent_p4_pi2 = results_p4_4ls_pi2_error\n",
    "error_higher_levels_p4_pi = error_coherent_p4_pi - results_p4_tls_pi_error\n",
    "error_higher_levels_p4_pi2 = error_coherent_p4_pi2 - results_p4_tls_pi2_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages over pi and pi2\n",
    "error_non_rwa_p1 = (results_p1_tls_pi_error + results_p1_tls_pi2_error)/2\n",
    "error_higher_levels_p1 = (error_higher_levels_p1_pi + error_higher_levels_p1_pi2)/2\n",
    "error_leakage_p1 = (leakage_p1_pi + leakage_p1_pi2)/2\n",
    "\n",
    "error_non_rwa_p2 = (results_p2_tls_pi_error + results_p2_tls_pi2_error)/2\n",
    "error_higher_levels_p2 = (error_higher_levels_p2_pi + error_higher_levels_p2_pi2)/2\n",
    "error_leakage_p2 = (leakage_p2_pi + leakage_p2_pi2)/2\n",
    "\n",
    "error_non_rwa_p3 = (results_p2_tls_pi_error + results_p2_tls_pi2_error)/2\n",
    "error_higher_levels_p3 = (error_higher_levels_p3_pi + error_higher_levels_p3_pi2)/2\n",
    "error_leakage_p3 = (leakage_p3_pi + leakage_p3_pi2)/2\n",
    "\n",
    "error_non_rwa_p4 = (results_p4_tls_pi_error + results_p4_tls_pi2_error)/2\n",
    "error_higher_levels_p4 = (error_higher_levels_p4_pi + error_higher_levels_p4_pi2)/2\n",
    "error_leakage_p4 = (leakage_p4_pi + leakage_p4_pi2)/2\n",
    "\n",
    "# Get stds\n",
    "rb_stds_p1 = np.flip(results_errors[:10:2])\n",
    "prb_stds_p1 = np.flip(results_errors[1:11:2])\n",
    "rb_stds_p2 = np.flip(results_errors[10:20:2])\n",
    "prb_stds_p2 = np.flip(results_errors[11:21:2])\n",
    "rb_stds_p3 = np.flip(results_errors[20:30:2])\n",
    "prb_stds_p3 = np.flip(results_errors[21:31:2])\n",
    "rb_stds_p4 = results_errors[-2]\n",
    "prb_stds_p4 = results_errors[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#f1a226\", \"#298c8c\", \"#8C3C29\", \"#8C2983\"]\n",
    "\n",
    "error_names = (\"RB-PRB\", \"RB-Decoh.\", \"Non-RWA\", \"Higher levels\", \"Leakage\")\n",
    "x = np.arange(len(error_names))\n",
    "width = 0.19\n",
    "\n",
    "# fig,ax = plt.subplots(len(tgs), 1, figsize=(8.5,3*len(tgs)), dpi=300)\n",
    "fig,ax = plt.subplots(len(tgs), 1, figsize=(9,3.2*len(tgs)), dpi=300)\n",
    "\n",
    "labels = {\n",
    "    \"Protocol 1\": \"No errors\",\n",
    "    \"Protocol 2\": \"Non-RWA errors\",\n",
    "    \"Protocol 3\": \"All errors\",\n",
    "    \"Protocol 4\": \"Orbit\",\n",
    "}\n",
    "\n",
    "for idx,tg in enumerate(tgs):\n",
    "    protocols = {\n",
    "        \"Protocol 1\": (errors_p1_measured[idx]-prb_p1_measured[idx], errors_p1_measured[idx]-coherence_limit[idx], error_non_rwa_p1[idx], error_higher_levels_p1[idx], error_leakage_p1[idx]),\n",
    "        \"Protocol 2\": (errors_p2_measured[idx]-prb_p2_measured[idx], errors_p2_measured[idx]-coherence_limit[idx], error_non_rwa_p2[idx], error_higher_levels_p2[idx], error_leakage_p2[idx]),\n",
    "        \"Protocol 3\": (errors_p3_measured[idx]-prb_p3_measured[idx], errors_p3_measured[idx]-coherence_limit[idx], error_non_rwa_p3[idx], error_higher_levels_p3[idx], error_leakage_p3[idx]),\n",
    "        \"Protocol 4\": (errors_p4_measured[idx]-prb_p4_measured[idx], errors_p4_measured[idx]-coherence_limit[idx], error_non_rwa_p4[idx], error_higher_levels_p4[idx], error_leakage_p4[idx]),\n",
    "    }\n",
    "    \n",
    "    multiplier = 0\n",
    "    for i, (attribute, measurement) in enumerate(protocols.items()):\n",
    "        offset = width * multiplier\n",
    "        rects = ax[len(tgs)-idx-1].bar(x + offset, measurement, width, label=labels[attribute], color=color_list[i])\n",
    "        multiplier += 1\n",
    "\n",
    "    ax[len(tgs)-idx-1].text(0.16, 0.033, rf\"{np.round(tgs[idx]*1e9,1)} ns\", fontsize=18)\n",
    "\n",
    "    # Plot errorbars\n",
    "    (_, caps1, _) = ax[len(tgs)-idx-1].errorbar(0*width, protocols[\"Protocol 1\"][0], yerr=rb_stds_p1[idx]+prb_stds_p1[idx], capsize=9, color=color_list[0])\n",
    "    (_, caps2, _) = ax[len(tgs)-idx-1].errorbar(1*width, protocols[\"Protocol 2\"][0], yerr=rb_stds_p2[idx]+prb_stds_p2[idx], capsize=9, color=color_list[1])\n",
    "    (_, caps3, _) = ax[len(tgs)-idx-1].errorbar(2*width, protocols[\"Protocol 3\"][0], yerr=rb_stds_p3[idx]+prb_stds_p3[idx], capsize=9, color=color_list[2])\n",
    "    (_, caps4, _) = ax[len(tgs)-idx-1].errorbar(1+0*width, protocols[\"Protocol 1\"][1], yerr=rb_stds_p1[idx], capsize=9, color=color_list[0])\n",
    "    (_, caps5, _) = ax[len(tgs)-idx-1].errorbar(1+1*width, protocols[\"Protocol 2\"][1], yerr=rb_stds_p2[idx], capsize=9, color=color_list[1])\n",
    "    (_, caps6, _) = ax[len(tgs)-idx-1].errorbar(1+2*width, protocols[\"Protocol 3\"][1], yerr=rb_stds_p3[idx], capsize=9, color=color_list[2])\n",
    "\n",
    "    if idx==0:\n",
    "        (_, caps7, _) = ax[len(tgs)-idx-1].errorbar(3*width, protocols[\"Protocol 4\"][0], yerr=rb_stds_p4+prb_stds_p4, capsize=9, color=color_list[3])\n",
    "        (_, caps8, _) = ax[len(tgs)-idx-1].errorbar(1+3*width, protocols[\"Protocol 4\"][1], yerr=rb_stds_p4, capsize=9, color=color_list[3])\n",
    "    else:\n",
    "        caps7 = caps8 = ()\n",
    "\n",
    "    for cap in caps1+caps2+caps3+caps3+caps4+caps5+caps6+caps7+caps8:\n",
    "        cap.set_markeredgewidth(1.5)\n",
    "\n",
    "for _ax in ax:\n",
    "    _ax.set_yscale(\"log\")\n",
    "    _ax.set_ylabel('Error')\n",
    "    _ax.set_ylim(1e-12, 1)\n",
    "\n",
    "for _ax in ax[:-1]:\n",
    "    _ax.set_xticks(x + width*1.5, [\"\"]*len(error_names))\n",
    "\n",
    "ax[-1].set_xticks(x + width*1.5, error_names)\n",
    "ax[0].legend(loc=(0.665,0.51), frameon=False, labelspacing=0.4)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"error-budget.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [\"#f1a226\", \"#298c8c\", \"#8C3C29\", \"#8C2983\"]\n",
    "\n",
    "error_names = (\"RB-PRB\", \"RB-Decoh.\", \"Non-RWA\", \"Higher levels\", \"Leakage\")\n",
    "x = np.arange(len(error_names))\n",
    "width = 0.19\n",
    "\n",
    "fig,ax = plt.subplots(len(tgs), 1, figsize=(8.5,3*len(tgs)), dpi=300)\n",
    "\n",
    "for idx,tg in enumerate(tgs):\n",
    "    protocols_pi2 = {\n",
    "        \"Protocol 1\": (errors_p1_measured[idx]-prb_p1_measured[idx], errors_p1_measured[idx]-coherence_limit[idx], results_p1_tls_pi2_error[idx], error_higher_levels_p1_pi2[idx], leakage_p1_pi2[idx]),\n",
    "        \"Protocol 2\": (errors_p2_measured[idx]-prb_p2_measured[idx], errors_p2_measured[idx]-coherence_limit[idx], results_p2_tls_pi2_error[idx], error_higher_levels_p2_pi2[idx], leakage_p2_pi2[idx]),\n",
    "        \"Protocol 3\": (errors_p3_measured[idx]-prb_p3_measured[idx], errors_p3_measured[idx]-coherence_limit[idx], results_p2_tls_pi2_error[idx], error_higher_levels_p3_pi2[idx], leakage_p3_pi2[idx]),\n",
    "        \"Protocol 4\": (errors_p4_measured[idx]-prb_p4_measured[idx], errors_p4_measured[idx]-coherence_limit[idx], results_p4_tls_pi2_error[idx], error_higher_levels_p4_pi2[idx], leakage_p4_pi2[idx]),\n",
    "    }\n",
    "\n",
    "    protocols_pi = {\n",
    "        \"Protocol 1\": (results_p1_tls_pi_error[idx], error_higher_levels_p1_pi[idx], leakage_p1_pi[idx]),\n",
    "        \"Protocol 2\": (results_p2_tls_pi_error[idx], error_higher_levels_p2_pi[idx], leakage_p2_pi[idx]),\n",
    "        \"Protocol 3\": (results_p2_tls_pi_error[idx], error_higher_levels_p3_pi[idx], leakage_p3_pi[idx]),\n",
    "        \"Protocol 4\": (results_p4_tls_pi_error[idx], error_higher_levels_p4_pi[idx], leakage_p4_pi[idx]),\n",
    "    }\n",
    "    \n",
    "    multiplier = 0\n",
    "    for i, (attribute, measurement) in enumerate(protocols_pi2.items()):\n",
    "        offset = width * multiplier\n",
    "        rects = ax[len(tgs)-idx-1].bar(x[2:] + offset, protocols_pi[attribute], width, color=color_list[i], alpha=0.5)\n",
    "        rects = ax[len(tgs)-idx-1].bar(x + offset, measurement, width, label=attribute, color=color_list[i])\n",
    "        multiplier += 1\n",
    "\n",
    "    ax[len(tgs)-idx-1].text(0.16, 0.033, rf\"{np.round(tgs[idx]*1e9,1)} ns\", fontsize=18)\n",
    "\n",
    "    # Plot errorbars\n",
    "    (_, caps1, _) = ax[len(tgs)-idx-1].errorbar(0*width, protocols_pi2[\"Protocol 1\"][0], yerr=rb_stds_p1[idx]+prb_stds_p1[idx], capsize=9, color=color_list[0])\n",
    "    (_, caps2, _) = ax[len(tgs)-idx-1].errorbar(1*width, protocols_pi2[\"Protocol 2\"][0], yerr=rb_stds_p2[idx]+prb_stds_p2[idx], capsize=9, color=color_list[1])\n",
    "    (_, caps3, _) = ax[len(tgs)-idx-1].errorbar(2*width, protocols_pi2[\"Protocol 3\"][0], yerr=rb_stds_p3[idx]+prb_stds_p3[idx], capsize=9, color=color_list[2])\n",
    "    (_, caps4, _) = ax[len(tgs)-idx-1].errorbar(1+0*width, protocols_pi2[\"Protocol 1\"][1], yerr=rb_stds_p1[idx], capsize=9, color=color_list[0])\n",
    "    (_, caps5, _) = ax[len(tgs)-idx-1].errorbar(1+1*width, protocols_pi2[\"Protocol 2\"][1], yerr=rb_stds_p2[idx], capsize=9, color=color_list[1])\n",
    "    (_, caps6, _) = ax[len(tgs)-idx-1].errorbar(1+2*width, protocols_pi2[\"Protocol 3\"][1], yerr=rb_stds_p3[idx], capsize=9, color=color_list[2])\n",
    "\n",
    "    if idx==0:\n",
    "        (_, caps7, _) = ax[len(tgs)-idx-1].errorbar(3*width, protocols_pi2[\"Protocol 4\"][0], yerr=rb_stds_p4+prb_stds_p4, capsize=9, color=color_list[3])\n",
    "        (_, caps8, _) = ax[len(tgs)-idx-1].errorbar(1+3*width, protocols_pi2[\"Protocol 4\"][1], yerr=rb_stds_p4, capsize=9, color=color_list[3])\n",
    "    else:\n",
    "        caps7 = caps8 = ()\n",
    "\n",
    "    for cap in caps1+caps2+caps3+caps3+caps4+caps5+caps6+caps7+caps8:\n",
    "        cap.set_markeredgewidth(1.5)\n",
    "\n",
    "for _ax in ax:\n",
    "    _ax.set_yscale(\"log\")\n",
    "    _ax.set_ylabel('Error')\n",
    "    _ax.set_ylim(1e-12, 1)\n",
    "\n",
    "for _ax in ax[:-1]:\n",
    "    _ax.set_xticks(x + width*1.5, [\"\"]*len(error_names))\n",
    "\n",
    "ax[-1].set_xticks(x + width*1.5, error_names)\n",
    "ax[0].legend(loc=(0.72,0.41))\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"error-budget.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppps = np.linspace(-0.5, 0.5, 31)\n",
    "detunings = np.linspace(-5, 5, 31)\n",
    "# Interp objs for heatmaps\n",
    "xx_interp = interp1d(ppps, np.arange(len(ppps)))\n",
    "yy_interp = interp1d(detunings, len(detunings) - np.arange(len(detunings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241202/\", start=104205, stop=151614)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.00396\n",
    "fit_detuning = -0.0198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33.333 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241202/\", start=151632, stop=201258)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.00673\n",
    "fit_detuning =  0.0393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.666 ns\n",
    "data_folders = np.concatenate((\n",
    "    get_data_folders(base_dir+\"20241202/\", start=201318, stop=235959),\n",
    "    get_data_folders(base_dir+\"20241203/\", start=0, stop=12638),\n",
    "))\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.0181\n",
    "fit_detuning =  0.0436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241203/\", start=12657, stop=64412)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.0534\n",
    "fit_detuning = -0.0014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.333 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241203/\", start=64434, stop=123439)\n",
    "fit_ppp      = -0.19712912\n",
    "fit_detuning = 0.02940773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241214/\", start=91854, stop=113013)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.00396\n",
    "fit_detuning = -0.0198\n",
    "\n",
    "# Remove index of failed experiment\n",
    "for i,data_folder in enumerate(data_folders):\n",
    "    if data_folder.split(\"/\")[-1].split(\"-\")[1]==\"110837\":\n",
    "        del data_folders[i+1]\n",
    "        del data_folders[i]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33.333 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241214/\", start=113022, stop=135738)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.00396\n",
    "fit_detuning = -0.0198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26.666 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241214/\", start=135748, stop=164220)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.11062705\n",
    "fit_detuning = 0.05008554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241214/\", start=164230, stop=193539)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.00396\n",
    "fit_detuning = -0.0198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.333 ns\n",
    "data_folders = get_data_folders(base_dir+\"20241214/\", start=193550, stop=223419)\n",
    "# Fitted ppp and detuning (fit made using the code below)\n",
    "fit_ppp      = -0.00396\n",
    "fit_detuning = -0.0198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_contrast_pi = np.zeros(len(detunings)*len(ppps))\n",
    "results_contrast_pi2 = np.zeros(len(detunings)*len(ppps))\n",
    "f01s = np.zeros(len(detunings)*len(ppps))\n",
    "\n",
    "for i,data_folder in enumerate(data_folders):\n",
    "    if i%2!=0:\n",
    "        continue\n",
    "\n",
    "    with h5py.File(data_folder+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0 = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "    n = len(counts_0)//2\n",
    "    results_contrast_pi[i//2] = np.max(counts_0[:n]) - np.min(counts_0[:n])\n",
    "    results_contrast_pi2[i//2] = np.max(counts_0[n:]) - np.min(counts_0[n:])\n",
    "\n",
    "results_pi  = results_contrast_pi.reshape((len(detunings), len(ppps)))\n",
    "results_pi2 = results_contrast_pi2.reshape((len(detunings), len(ppps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = fig_prepare(\"ppp\", \"Detuning\")\n",
    "ax.grid(False)\n",
    "ax = sns.heatmap(np.flip(results_pi,axis=0), xticklabels=ppps, yticklabels=np.round(np.flip(detunings),2), cmap=\"Blues\", cbar_kws={\"label\": \"Phase error\"}, ax=ax)\n",
    "\n",
    "x_interp = interp1d(np.arange(len(ppps)), ppps)\n",
    "y_interp = interp1d(np.arange(len(detunings)), np.flip(detunings))\n",
    "\n",
    "idx = np.linspace(0,len(ppps)-1,5)\n",
    "idx2 = np.linspace(0,len(detunings)-1,5)\n",
    "\n",
    "ax.set_xticks([0.5+i for i in idx])\n",
    "ax.set_yticks([0.5+i for i in idx2])\n",
    "ax.set(xlabel=r\"$\\lambda$\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "ax.set_xticklabels(np.round(x_interp(idx), 3), rotation=0)\n",
    "ax.set_yticklabels(np.round(y_interp(idx2), 2))\n",
    "\n",
    "ax.set_title(r\"$\\pi$\", fontsize=18)\n",
    "fig.set_size_inches(5.5,3.8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"3D-contrast-pi.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = fig_prepare(\"ppp\", \"Detuning\")\n",
    "ax.grid(False)\n",
    "ax = sns.heatmap(np.flip(results_pi2,axis=0), xticklabels=ppps, yticklabels=np.round(np.flip(detunings),2), cmap=\"Blues\", cbar_kws={\"label\": \"Phase error\"}, ax=ax)\n",
    "\n",
    "x_interp = interp1d(np.arange(len(ppps)), ppps)\n",
    "y_interp = interp1d(np.arange(len(detunings)), np.flip(detunings))\n",
    "\n",
    "idx = np.linspace(0,len(ppps)-1,5)\n",
    "idx2 = np.linspace(0,len(detunings)-1,5)\n",
    "\n",
    "ax.set_xticks([0.5+i for i in idx])\n",
    "ax.set_yticks([0.5+i for i in idx2])\n",
    "ax.set(xlabel=r\"$\\lambda$\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "ax.set_xticklabels(np.round(x_interp(idx), 3), rotation=0)\n",
    "ax.set_yticklabels(np.round(y_interp(idx2), 2))\n",
    "\n",
    "ax.set_title(r\"$\\pi/2$\", fontsize=18)\n",
    "fig.set_size_inches(5.5,3.8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"3D-contrast-pi2.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = fig_prepare(\"ppp\", \"Detuning\")\n",
    "ax.grid(False)\n",
    "ax = sns.heatmap(np.flip(results_pi*results_pi2,axis=0), xticklabels=ppps, yticklabels=np.round(np.flip(detunings),2), cmap=\"Blues\", cbar_kws={\"label\": \"Phase error\"}, ax=ax)\n",
    "\n",
    "x_interp = interp1d(np.arange(len(ppps)), ppps)\n",
    "y_interp = interp1d(np.arange(len(detunings)), np.flip(detunings))\n",
    "\n",
    "idx = np.linspace(0,len(ppps)-1,5)\n",
    "idx2 = np.linspace(0,len(detunings)-1,5)\n",
    "\n",
    "ax.set_xticks([0.5+i for i in idx])\n",
    "ax.set_yticks([0.5+i for i in idx2])\n",
    "ax.set(xlabel=r\"PPP $\\lambda$\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "ax.set_xticklabels(np.round(x_interp(idx), 3), rotation=0)\n",
    "ax.set_yticklabels(np.round(y_interp(idx2), 2))\n",
    "\n",
    "ax.plot(xx_interp(fit_ppp)+0.5, yy_interp(fit_detuning)-0.5, marker=\"x\", color=colors[\"red\"], markersize=15, markeredgewidth=3)\n",
    "\n",
    "ax.set_title(r\"Intersect\", fontsize=18)\n",
    "fig.set_size_inches(5.5,3.8)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"3D-intersect.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_phase_errors_1 = (results_pi-np.min(results_pi))/(np.max(results_pi)-np.min(results_pi))\n",
    "data_phase_errors_2 = (results_pi2-np.min(results_pi2))/(np.max(results_pi2)-np.min(results_pi2))\n",
    "data_phase_errors_3 = data_phase_errors_1*data_phase_errors_2\n",
    "\n",
    "x_interp = interp1d(np.arange(len(ppps)), ppps)\n",
    "y_interp = interp1d(np.arange(len(detunings)), np.flip(detunings))\n",
    "idx = np.linspace(0,len(ppps)-1,5)\n",
    "idx2 = np.linspace(0,len(detunings)-1,5)\n",
    "norm = Normalize(vmin=0, vmax=1)\n",
    "\n",
    "fig,ax = plt.subplots(1, 3, figsize=(13.5,3.9), dpi=300, width_ratios=[1,1,1.2])\n",
    "\n",
    "for _ax in ax:\n",
    "    _ax.grid(False)\n",
    "\n",
    "\n",
    "## Plot figure (a)\n",
    "ax[0] = sns.heatmap(np.flip(data_phase_errors_1,axis=0), \n",
    "                    xticklabels=ppps, \n",
    "                    yticklabels=np.round(np.flip(detunings),2), \n",
    "                    cmap=\"Blues_r\", \n",
    "                    norm=norm,\n",
    "                    cbar=False, \n",
    "                    ax=ax[0])\n",
    "\n",
    "ax[0].set_xticks([0.5+i for i in idx])\n",
    "ax[0].set_yticks([0.5+i for i in idx2])\n",
    "ax[0].set(xlabel=r\"$\\lambda$\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "ax[0].set_xticklabels(np.round(x_interp(idx), 3), rotation=0)\n",
    "ax[0].set_yticklabels(np.round(y_interp(idx2), 2))\n",
    "\n",
    "ax[0].set_title(r\"$\\pi$\", fontsize=18)\n",
    "\n",
    "## Plot figure (b)\n",
    "ax[1] = sns.heatmap(np.flip(data_phase_errors_2,axis=0), \n",
    "                    xticklabels=ppps, \n",
    "                    yticklabels=np.round(np.flip(detunings),2), \n",
    "                    cmap=\"Blues_r\", \n",
    "                    norm=norm,\n",
    "                    cbar=False, \n",
    "                    ax=ax[1])\n",
    "\n",
    "ax[1].set_xticks([0.5+i for i in idx])\n",
    "ax[1].set_yticks([0.5+i for i in idx2])\n",
    "ax[1].set(xlabel=r\"$\\lambda$\", ylabel=r\"\")\n",
    "ax[1].set_xticklabels(np.round(x_interp(idx), 3), rotation=0)\n",
    "ax[1].set_yticklabels([\"\"]*len(idx2))\n",
    "\n",
    "ax[1].set_title(r\"$\\pi/2$\", fontsize=18)\n",
    "\n",
    "## Plot figure (c)\n",
    "ax[2] = sns.heatmap(np.flip(data_phase_errors_3,axis=0), \n",
    "                    xticklabels=ppps, \n",
    "                    yticklabels=np.round(np.flip(detunings),2), \n",
    "                    cmap=\"Blues_r\", \n",
    "                    norm=norm,\n",
    "                    cbar_kws={\"label\": \"Phase error (a.u.)\",\n",
    "                              \"ticks\":[0, 0.25, 0.5, 0.75, 1]},\n",
    "                    ax=ax[2])\n",
    "\n",
    "ax[2].set_xticks([0.5+i for i in idx])\n",
    "ax[2].set_yticks([0.5+i for i in idx2])\n",
    "ax[2].set(xlabel=r\"$\\lambda$\", ylabel=r\"\")\n",
    "ax[2].set_xticklabels(np.round(x_interp(idx), 3), rotation=0)\n",
    "ax[2].set_yticklabels([\"\"]*len(idx2))\n",
    "\n",
    "ax[2].plot(xx_interp(fit_ppp)+0.5, yy_interp(fit_detuning)-0.5, marker=\"x\", color=colors[\"red\"], markersize=15, markeredgewidth=3)\n",
    "\n",
    "ax[2].set_title(r\"Intersect\", fontsize=18)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"figures-presentations/experimental-heatmaps.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fit_pi2_ppp   = []\n",
    "results_fit_pi2_delta = []\n",
    "for i in range(results_pi2.shape[0]):\n",
    "    if np.min(results_pi2[i,:])>0.25:\n",
    "        continue\n",
    "\n",
    "    results_fit_pi2_delta.append(detunings[i])\n",
    "    results_fit_pi2_ppp.append(ppps[np.argmin(results_pi2[i,:])])\n",
    "\n",
    "results_fit_pi_ppp   = []\n",
    "results_fit_pi_delta = []\n",
    "# Change idx0 and idx1 to limit range for pi scan\n",
    "idx0 = np.argmin(np.square(ppps+0.4))\n",
    "idx1 = np.argmin(np.square(ppps-0.1))\n",
    "for i in range(results_pi.shape[0]):\n",
    "    if np.min(results_pi[i,idx0:idx1])>0.4:\n",
    "        continue\n",
    "\n",
    "    results_fit_pi_delta.append(detunings[i])\n",
    "    results_fit_pi_ppp.append(ppps[idx0+np.argmin(results_pi[i,idx0:idx1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.polyfit(results_fit_pi2_ppp, results_fit_pi2_delta, 2)\n",
    "p_pi2 = np.poly1d(z)\n",
    "xx_pi2 = np.linspace(np.min(results_fit_pi2_ppp), np.max(results_fit_pi2_ppp), 101)\n",
    "\n",
    "z = np.polyfit(results_fit_pi_ppp, results_fit_pi_delta, 2)\n",
    "p_pi = np.poly1d(z)\n",
    "xx_pi = np.linspace(np.min(results_fit_pi_ppp), np.max(results_fit_pi_ppp), 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = fig_prepare(r\"PPP $\\lambda$\", r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "ax.plot(xx_pi2, p_pi2(xx_pi2))\n",
    "ax.plot(xx_pi, p_pi(xx_pi))\n",
    "ax.plot(results_fit_pi2_ppp, results_fit_pi2_delta, linestyle=\"\", marker=\".\")\n",
    "ax.plot(results_fit_pi_ppp, results_fit_pi_delta, linestyle=\"\", marker=\".\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"fit-linecuts.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "    return np.square(p_pi(x)-p_pi2(x))\n",
    "\n",
    "# Potentially change x0 and bounds\n",
    "res = minimize(fun, x0=[-0.2], bounds=((-0.4,0),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[\"x\"], p_pi(res[\"x\"]), p_pi2(res[\"x\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap final figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_data = load_dataset(\"20250124-131553\", folder_name=\"extended-data\", json_fname=\"extended_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgs = [13.3, 20, 26.7, 33.3, 40]\n",
    "\n",
    "data_folders = [\n",
    "    # 13 ns\n",
    "    get_data_folders(base_dir+\"20241214/\", start=193550, stop=223419),\n",
    "    # 20 ns\n",
    "    get_data_folders(base_dir+\"20241214/\", start=164230, stop=193539),\n",
    "    # 26.666 ns\n",
    "    get_data_folders(base_dir+\"20241214/\", start=135748, stop=164220),\n",
    "    # 33.333 ns\n",
    "    get_data_folders(base_dir+\"20241214/\", start=113022, stop=135738),\n",
    "    # 40 ns\n",
    "    ## requires trickery\n",
    "]\n",
    "\n",
    "data_folders_40ns = get_data_folders(base_dir+\"20241214/\", start=91854, stop=113013)\n",
    "\n",
    "# Remove index of failed experiment\n",
    "# (This experiment crashed and was automatically rerun)\n",
    "for i,data_folder in enumerate(data_folders_40ns):\n",
    "    if data_folder.split(\"/\")[-1].split(\"-\")[1]==\"110837\":\n",
    "        del data_folders_40ns[i+1]\n",
    "        del data_folders_40ns[i]\n",
    "        break\n",
    "\n",
    "data_folders.append(data_folders_40ns)\n",
    "\n",
    "\n",
    "# Setpoints\n",
    "ppps = np.linspace(-0.5, 0.5, 31)\n",
    "detunings = np.linspace(-5, 5, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_interp = interp1d(ppps, np.arange(len(ppps)))\n",
    "yy_interp = interp1d(detunings, len(detunings) - np.arange(len(detunings)))\n",
    "\n",
    "# Define values for axis ticks\n",
    "x_vals = np.array([-0.5, 0, 0.5])\n",
    "y_vals = np.array([-5, 0, 5])\n",
    "\n",
    "min1, max1 = 0, 1\n",
    "cmap = \"Blues_r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain experimental data\n",
    "exp_results_pi = np.zeros((len(tgs), len(detunings), len(ppps)))\n",
    "exp_results_pi2 = np.zeros((len(tgs), len(detunings), len(ppps)))\n",
    "\n",
    "for idx,tg in enumerate(tgs):\n",
    "    # Obtain measured contrasts for tg\n",
    "    results_contrast_pi = np.zeros(len(detunings)*len(ppps))\n",
    "    results_contrast_pi2 = np.zeros(len(detunings)*len(ppps))\n",
    "    f01s = np.zeros(len(detunings)*len(ppps))\n",
    "\n",
    "    for i,data_folder in enumerate(data_folders[idx]):\n",
    "        if i%2!=0:\n",
    "            continue\n",
    "\n",
    "        with h5py.File(data_folder+\"/dataset.hdf5\", \"r\") as f:\n",
    "            counts_0 = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "        n = len(counts_0)//2\n",
    "        results_contrast_pi[i//2] = np.max(counts_0[:n]) - np.min(counts_0[:n])\n",
    "        results_contrast_pi2[i//2] = np.max(counts_0[n:]) - np.min(counts_0[n:])\n",
    "\n",
    "    exp_results_pi[idx,:,:]  = results_contrast_pi.reshape((len(detunings), len(ppps)))\n",
    "    exp_results_pi2[idx,:,:] = results_contrast_pi2.reshape((len(detunings), len(ppps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3.4*8), dpi=300)\n",
    "gs = plt.GridSpec(10,2, figure=fig, height_ratios=[0.08,0.08,1,1,1,1,1,1,1,1], wspace=0.12, hspace=0.12)\n",
    "\n",
    "# Actual axis with data\n",
    "axs = np.empty((10,2), dtype=object)\n",
    "for i in range(8):\n",
    "    axs[i,0] = fig.add_subplot(gs[2+i,0])\n",
    "    axs[i,1] = fig.add_subplot(gs[2+i,1])\n",
    "\n",
    "# Axis for heatmap\n",
    "ax11 = fig.add_subplot(gs[0,:])\n",
    "# Axis for text\n",
    "ax12 = fig.add_subplot(gs[1,0])\n",
    "ax13 = fig.add_subplot(gs[1,1])\n",
    "\n",
    "ax12.set_axis_off()\n",
    "ax13.set_axis_off()\n",
    "ax12.text(0.31, 0, r\"Measured\", fontsize=18)\n",
    "ax13.text(0.31, 0, r\"Simulated\", fontsize=18)\n",
    "\n",
    "_tgs = [40, 33.3, 20, 13.3]\n",
    "_exp_results_pi = np.delete(exp_results_pi, 2, axis=0)\n",
    "_exp_results_pi2 = np.delete(exp_results_pi2, 2, axis=0)\n",
    "_didx = [4,3,1,0]\n",
    "for idx,tg in enumerate(_tgs):\n",
    "    didx = len(_tgs)-idx-1\n",
    "    # Get measured results\n",
    "    results_pi  = _exp_results_pi[didx,:,:]\n",
    "    results_pi2 = _exp_results_pi2[didx,:,:]\n",
    "\n",
    "    # Get numerical results\n",
    "    numerical_pi = extended_data[\"heatmaps_processed\"][f\"y{2*_didx[idx]}\"]\n",
    "    numerical_pi2 = extended_data[\"heatmaps_processed\"][f\"y{2*_didx[idx]+1}\"]\n",
    "\n",
    "    # Normalize all setpoints\n",
    "    results_pi = (results_pi - np.min(results_pi)) / (np.max(results_pi) - np.min(results_pi))\n",
    "    results_pi2 = (results_pi2 - np.min(results_pi2)) / (np.max(results_pi2) - np.min(results_pi2))\n",
    "    numerical_pi = (numerical_pi - np.min(numerical_pi)) / (np.max(numerical_pi) - np.min(numerical_pi))\n",
    "    numerical_pi2 = (numerical_pi2 - np.min(numerical_pi2)) / (np.max(numerical_pi2) - np.min(numerical_pi2))\n",
    "\n",
    "    ## Plot data\n",
    "    # Plot experimental pi/2\n",
    "    if idx==0:\n",
    "        # Only figure with scalebar\n",
    "        axs[2*idx,0] = sns.heatmap(data=np.flip(results_pi2, axis=0), \n",
    "                                   xticklabels=ppps, \n",
    "                                   yticklabels=np.flip(detunings), \n",
    "                                   cmap=cmap, \n",
    "                                   ax=axs[2*idx,0],\n",
    "                                   norm=Normalize(vmin=min1, vmax=max1),\n",
    "                                   cbar_ax=ax11,\n",
    "                                   cbar_kws={\"label\": \"Phase error (a.u.)\",\n",
    "                                             \"ticks\":[0, 0.25, 0.5, 0.75, 1],\n",
    "                                             \"orientation\": \"horizontal\",\n",
    "                                             \"location\": \"top\"})\n",
    "    else:\n",
    "        axs[2*idx,0] = sns.heatmap(data=np.flip(results_pi2, axis=0), \n",
    "                                   xticklabels=ppps, \n",
    "                                   yticklabels=np.flip(detunings), \n",
    "                                   cmap=cmap, \n",
    "                                   ax=axs[2*idx,0],\n",
    "                                   norm=Normalize(vmin=min1, vmax=max1),\n",
    "                                   cbar=False)\n",
    "\n",
    "    # Plot numerical pi/2\n",
    "    axs[2*idx,1] = sns.heatmap(data=numerical_pi2.T, \n",
    "                               xticklabels=ppps, \n",
    "                               yticklabels=np.flip(detunings), \n",
    "                               cmap=cmap, \n",
    "                               ax=axs[2*idx,1],\n",
    "                               norm=Normalize(vmin=min1, vmax=max1),\n",
    "                               cbar=False)\n",
    "\n",
    "    # Plot experimental pi\n",
    "    axs[2*idx+1,0] = sns.heatmap(data=np.flip(results_pi, axis=0), \n",
    "                                 xticklabels=ppps, \n",
    "                                 yticklabels=np.flip(detunings), \n",
    "                                 cmap=cmap, \n",
    "                                 ax=axs[2*idx+1,0],\n",
    "                                 norm=Normalize(vmin=min1, vmax=max1),\n",
    "                                 cbar=False)\n",
    "\n",
    "    # Plot numerical pi\n",
    "    axs[2*idx+1,1] = sns.heatmap(data=numerical_pi.T, \n",
    "                                 xticklabels=ppps, \n",
    "                                 yticklabels=np.flip(detunings), \n",
    "                                 cmap=cmap, \n",
    "                                 ax=axs[2*idx+1,1],\n",
    "                                 norm=Normalize(vmin=min1, vmax=max1),\n",
    "                                 cbar=False)\n",
    "\n",
    "    ## Plot labels and ticks\n",
    "    # Left top\n",
    "    axs[2*idx,0].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                            labels=[\"\"]*len(x_vals))\n",
    "    axs[2*idx,0].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                            labels=y_vals)\n",
    "    axs[2*idx,0].set(xlabel=r\"\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "\n",
    "    # Right top\n",
    "    axs[2*idx,1].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                            labels=[\"\"]*len(x_vals))\n",
    "    axs[2*idx,1].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                            labels=[\"\"]*len(y_vals))\n",
    "    axs[2*idx,1].set(xlabel=r\"\", ylabel=r\"\")\n",
    "\n",
    "    # Left bottom\n",
    "    if idx==len(_tgs)-1:\n",
    "        axs[2*idx+1,0].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                                  labels=x_vals,\n",
    "                                  rotation=0)\n",
    "        axs[2*idx+1,0].set(xlabel=r\"$\\lambda$\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "    else:\n",
    "        axs[2*idx+1,0].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                                  labels=[\"\"]*len(x_vals))\n",
    "        axs[2*idx+1,0].set(xlabel=r\"\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "    axs[2*idx+1,0].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                              labels=y_vals)\n",
    "    \n",
    "\n",
    "    # Right bottom\n",
    "    if idx==len(_tgs)-1:\n",
    "        axs[2*idx+1,1].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                                  labels=x_vals,\n",
    "                                  rotation=0)\n",
    "        axs[2*idx+1,1].set(xlabel=r\"$\\lambda$\", ylabel=r\"\")\n",
    "    else:\n",
    "        axs[2*idx+1,1].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                                  labels=[\"\"]*len(x_vals))\n",
    "        axs[2*idx+1,1].set(xlabel=r\"\", ylabel=r\"\")\n",
    "    axs[2*idx+1,1].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                              labels=[\"\"]*len(y_vals))\n",
    "\n",
    "    # Plot gate duration on right axis\n",
    "    _ax = axs[2*idx,1].twinx()\n",
    "    _ax.grid(False)\n",
    "    _ax.set_yticks([])\n",
    "    # _ax.set_xticks([])\n",
    "    _ax.spines['top'].set_visible(False)\n",
    "    _ax.spines['right'].set_visible(False)\n",
    "    _ax.spines['bottom'].set_visible(False)\n",
    "    _ax.spines['left'].set_visible(False)\n",
    "    _ax.set_ylabel(f\"{tg} ns\", rotation=270)\n",
    "    _ax.yaxis.set_label_coords(1.12, -0.05)\n",
    "    _ax.text(1.02, 0.45, r\"$\\pi/2$\", rotation=270, fontsize=18, transform=_ax.transAxes)\n",
    "    _ax.text(1.02, -0.65, r\"$\\pi$\", rotation=270, fontsize=18, transform=_ax.transAxes)\n",
    "\n",
    "fig.savefig(\"all-heatmaps.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final experimental figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init figure and axes\n",
    "fig = plt.figure(figsize=(10,16.5), dpi=300)\n",
    "gs = plt.GridSpec(6,2, figure=fig, height_ratios=[0.03, 0.02, 0.19, 0.19, 0.252, 0.25], wspace=0.12, hspace=0.12)\n",
    "\n",
    "# Ax for RB data figure\n",
    "ax0 = fig.add_subplot(gs[4,:])\n",
    "# Ax for error budget\n",
    "ax1 = fig.add_subplot(gs[5,:])\n",
    "# Ax for heatmap\n",
    "ax2 = fig.add_subplot(gs[0,:])\n",
    "# Ax for text\n",
    "ax3 = fig.add_subplot(gs[1,0])\n",
    "ax4 = fig.add_subplot(gs[1,1])\n",
    "# Ax for heatmaps\n",
    "axs = np.empty((2,2), dtype=object)\n",
    "for i in range(2):\n",
    "    axs[i,0] = fig.add_subplot(gs[2+i,0])\n",
    "    axs[i,1] = fig.add_subplot(gs[2+i,1])\n",
    "\n",
    "## Add text labels for heatmaps\n",
    "ax3.set_axis_off()\n",
    "ax4.set_axis_off()\n",
    "ax3.text(0.25, 0, r\"Experimental\", fontsize=18)\n",
    "ax4.text(0.32, 0, r\"Numerical\", fontsize=18)\n",
    "\n",
    "## Plot figure (a)\n",
    "results_tgs = figure_data[0][\"x0\"]\n",
    "results_errors = figure_data[0][\"y0\"]\n",
    "results_stds = figure_data[0][\"y1\"]\n",
    "\n",
    "xx = 1e-9 * np.linspace(np.min(results_tgs), np.max(results_tgs), 101)\n",
    "coherence_limit = 0.5 + 1/6 * np.exp(-xx/75e-6) + 1/3*np.exp(-xx/37e-6)\n",
    "coherence_limit = (1-coherence_limit)\n",
    "\n",
    "results_purity_p3 = results_errors[21:31:2]\n",
    "\n",
    "color_list = [\"#f1a226\", \"#298c8c\", \"#8C3C29\", \"#8C2983\"]\n",
    "ax0.set_yscale(\"log\")\n",
    "(_, caps1, _) = ax0.errorbar(results_tgs, results_errors[:10:2], yerr=results_stds[:10:2], linestyle=\"\", marker=\"^\", markersize=9, capsize=6, linewidth=2, color=color_list[0], label=\"Ideal RWA\")\n",
    "(_, caps2, _) = ax0.errorbar(results_tgs, results_errors[10:20:2], yerr=results_stds[10:20:2], linestyle=\"\", marker=\">\", markersize=9, capsize=6, linewidth=2, color=color_list[1], label=\"Non-RWA only\")\n",
    "(_, caps3, _) = ax0.errorbar(results_tgs, results_errors[20:30:2], yerr=results_stds[20:30:2], linestyle=\"\", marker=\"v\", markersize=9, capsize=6, linewidth=2, color=color_list[2], label=\"Non-RWA + MLS\")\n",
    "ax0.errorbar(results_tgs[-1], results_errors[-2], yerr=results_stds[-2], linestyle=\"\", marker=\"<\", markersize=9, capsize=6, linewidth=2, color=color_list[3], label=\"ORBIT\")\n",
    "ax0.plot(xx*1e9, coherence_limit, linewidth=2, color=\"#333\", label=\"Coherence limit\")\n",
    "ax0.plot(results_tgs, results_purity_p3, linewidth=2, color=\"#333\", linestyle=\"--\", label=\"PRB\")\n",
    "\n",
    "for cap in caps1+caps2+caps3:\n",
    "    cap.set_markeredgewidth(1.5)\n",
    "\n",
    "ax0.set_xticks(ticks=np.flip(results_tgs), \n",
    "               labels=[13.3, 20, 26.7, 33.3, 40])\n",
    "ax0.legend(loc=[0.33,0.66], frameon=False, ncol=2, labelspacing=0.4, columnspacing=0.9)\n",
    "# ax0.legend(loc=[0.1,0.75], frameon=False, ncol=3, labelspacing=0.4, columnspacing=0.9)\n",
    "ax0.set_yticks([1e-4,1e-3,1e-2,1e-1])\n",
    "ax0.set_ylabel(\"Error\")\n",
    "ax0.set_xlabel(r\"$t_g$ (ns)\")\n",
    "\n",
    "## Plot figure (b)\n",
    "error_names = (\"RB-PRB\", \"RB-Decoh.\", \"Non-RWA\", \"Higher levels\", \"Leakage\")\n",
    "labels = {\n",
    "    \"Protocol 1\": \"Ideal RWA\",\n",
    "    \"Protocol 2\": \"Non-RWA only\",\n",
    "    \"Protocol 3\": \"Non-RWA + MLS\",\n",
    "    \"Protocol 4\": \"ORBIT\",\n",
    "}\n",
    "x = np.arange(len(error_names))\n",
    "width = 0.19\n",
    "idx = 2\n",
    "protocols = {\n",
    "    \"Protocol 1\": (errors_p1_measured[idx]-prb_p1_measured[idx], errors_p1_measured[idx]-coherence_limit[idx], error_non_rwa_p1[idx], error_higher_levels_p1[idx], error_leakage_p1[idx]),\n",
    "    \"Protocol 2\": (errors_p2_measured[idx]-prb_p2_measured[idx], errors_p2_measured[idx]-coherence_limit[idx], error_non_rwa_p2[idx], error_higher_levels_p2[idx], error_leakage_p2[idx]),\n",
    "    \"Protocol 3\": (errors_p3_measured[idx]-prb_p3_measured[idx], errors_p3_measured[idx]-coherence_limit[idx], error_non_rwa_p3[idx], error_higher_levels_p3[idx], error_leakage_p3[idx]),\n",
    "    \"Protocol 4\": (errors_p4_measured[idx]-prb_p4_measured[idx], errors_p4_measured[idx]-coherence_limit[idx], error_non_rwa_p4[idx], error_higher_levels_p4[idx], error_leakage_p4[idx]),\n",
    "}\n",
    "\n",
    "# Plot bars\n",
    "multiplier = 0\n",
    "for i, (attribute, measurement) in enumerate(protocols.items()):\n",
    "    offset = width * multiplier\n",
    "    rects = ax1.bar(x + offset, measurement, width, label=labels[attribute], color=color_list[i])    \n",
    "    multiplier += 1\n",
    "\n",
    "# Plot errorbars\n",
    "rb_stds_p1 = results_errors[:10:2]\n",
    "prb_stds_p1 = results_errors[1:11:2]\n",
    "rb_stds_p2 = results_errors[10:20:2]\n",
    "prb_stds_p2 = results_errors[11:21:2]\n",
    "rb_stds_p3 = results_errors[20:30:2]\n",
    "prb_stds_p3 = results_errors[21:31:2]\n",
    "(_, caps1, _) = ax1.errorbar(0*width, protocols[\"Protocol 1\"][0], yerr=rb_stds_p1[idx]+prb_stds_p1[idx], capsize=9, color=color_list[0])\n",
    "(_, caps2, _) = ax1.errorbar(1*width, protocols[\"Protocol 2\"][0], yerr=rb_stds_p2[idx]+prb_stds_p2[idx], capsize=9, color=color_list[1])\n",
    "(_, caps3, _) = ax1.errorbar(2*width, protocols[\"Protocol 3\"][0], yerr=rb_stds_p3[idx]+prb_stds_p3[idx], capsize=9, color=color_list[2])\n",
    "(_, caps4, _) = ax1.errorbar(1+0*width, protocols[\"Protocol 1\"][1], yerr=rb_stds_p1[idx], capsize=9, color=color_list[0])\n",
    "(_, caps5, _) = ax1.errorbar(1+1*width, protocols[\"Protocol 2\"][1], yerr=rb_stds_p2[idx], capsize=9, color=color_list[1])\n",
    "(_, caps6, _) = ax1.errorbar(1+2*width, protocols[\"Protocol 3\"][1], yerr=rb_stds_p3[idx], capsize=9, color=color_list[2])\n",
    "\n",
    "for cap in caps1+caps2+caps3+caps3+caps4+caps5+caps6:\n",
    "    cap.set_markeredgewidth(1.5)\n",
    "\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_ylabel('Error')\n",
    "ax1.set_ylim(1e-12, 1)\n",
    "ax1.set_xticks(x + width*1.5, error_names)\n",
    "ax1.legend(loc=(0.66,0.555), frameon=False, labelspacing=0.4)\n",
    "\n",
    "## Plot figure (c)\n",
    "didx = 2\n",
    "# Get measured results\n",
    "results_pi  = exp_results_pi[didx,:,:]\n",
    "results_pi2 = exp_results_pi2[didx,:,:]\n",
    "\n",
    "# Get numerical results\n",
    "numerical_pi = extended_data[\"heatmaps_processed\"][f\"y{2*didx}\"]\n",
    "numerical_pi2 = extended_data[\"heatmaps_processed\"][f\"y{2*didx+1}\"]\n",
    "\n",
    "# Normalize all setpoints\n",
    "results_pi = (results_pi - np.min(results_pi)) / (np.max(results_pi) - np.min(results_pi))\n",
    "results_pi2 = (results_pi2 - np.min(results_pi2)) / (np.max(results_pi2) - np.min(results_pi2))\n",
    "numerical_pi = (numerical_pi - np.min(numerical_pi)) / (np.max(numerical_pi) - np.min(numerical_pi))\n",
    "numerical_pi2 = (numerical_pi2 - np.min(numerical_pi2)) / (np.max(numerical_pi2) - np.min(numerical_pi2))\n",
    "\n",
    "## Plot data\n",
    "# Plot experimental pi/2\n",
    "axs[0,0] = sns.heatmap(data=np.flip(results_pi2, axis=0), \n",
    "                       xticklabels=ppps, \n",
    "                       yticklabels=np.flip(detunings), \n",
    "                       cmap=cmap, \n",
    "                       ax=axs[0,0],\n",
    "                       norm=Normalize(vmin=min1, vmax=max1),\n",
    "                       cbar_ax=ax2,\n",
    "                       cbar_kws={\"label\": \"Phase error (a.u.)\",\n",
    "                                 \"ticks\":[0, 0.25, 0.5, 0.75, 1],\n",
    "                                 \"orientation\": \"horizontal\",\n",
    "                                 \"location\": \"top\"})\n",
    "\n",
    "# Plot numerical pi/2\n",
    "axs[0,1] = sns.heatmap(data=numerical_pi2.T, \n",
    "                       xticklabels=ppps, \n",
    "                       yticklabels=np.flip(detunings), \n",
    "                       cmap=cmap, \n",
    "                       ax=axs[0,1],\n",
    "                       norm=Normalize(vmin=min1, vmax=max1),\n",
    "                       cbar=False)\n",
    "\n",
    "# Plot experimental pi\n",
    "axs[1,0] = sns.heatmap(data=np.flip(results_pi, axis=0), \n",
    "                       xticklabels=ppps, \n",
    "                       yticklabels=np.flip(detunings), \n",
    "                       cmap=cmap, \n",
    "                       ax=axs[1,0],\n",
    "                       norm=Normalize(vmin=min1, vmax=max1),\n",
    "                       cbar=False)\n",
    "\n",
    "# Plot numerical pi\n",
    "axs[1,1] = sns.heatmap(data=numerical_pi.T, \n",
    "                       xticklabels=ppps, \n",
    "                       yticklabels=np.flip(detunings), \n",
    "                       cmap=cmap, \n",
    "                       ax=axs[1,1],\n",
    "                       norm=Normalize(vmin=min1, vmax=max1),\n",
    "                       cbar=False)\n",
    "\n",
    "## Plot labels and ticks\n",
    "# Left top\n",
    "axs[0,0].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                    labels=[\"\"]*len(x_vals))\n",
    "axs[0,0].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                    labels=y_vals)\n",
    "axs[0,0].set(xlabel=r\"\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "\n",
    "# Right top\n",
    "axs[0,1].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                    labels=[\"\"]*len(x_vals))\n",
    "axs[0,1].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                    labels=[\"\"]*len(y_vals))\n",
    "axs[0,1].set(xlabel=r\"\", ylabel=r\"\")\n",
    "\n",
    "# Left bottom\n",
    "axs[1,0].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                    labels=x_vals,\n",
    "                    rotation=0)\n",
    "axs[1,0].set(xlabel=r\"$\\lambda$\", ylabel=r\"$\\Delta/2\\pi$ (MHz)\")\n",
    "axs[1,0].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                    labels=y_vals)\n",
    "\n",
    "\n",
    "# Right bottom\n",
    "axs[1,1].set_xticks(ticks=[0.5+i for i in xx_interp(x_vals)],\n",
    "                    labels=x_vals,\n",
    "                    rotation=0)\n",
    "axs[1,1].set(xlabel=r\"$\\lambda$\", ylabel=r\"\")\n",
    "axs[1,1].set_yticks(ticks=[-0.5+i for i in yy_interp(y_vals)],\n",
    "                    labels=[\"\"]*len(y_vals))\n",
    "\n",
    "# Plot gate duration on right axis\n",
    "_ax = axs[0,1].twinx()\n",
    "_ax.grid(False)\n",
    "_ax.set_yticks([])\n",
    "_ax.spines['top'].set_visible(False)\n",
    "_ax.spines['right'].set_visible(False)\n",
    "_ax.spines['bottom'].set_visible(False)\n",
    "_ax.spines['left'].set_visible(False)\n",
    "_ax.text(1.02, 0.45, r\"$\\pi/2$\", rotation=270, fontsize=18, transform=_ax.transAxes)\n",
    "_ax.text(1.02, -0.65, r\"$\\pi$\", rotation=270, fontsize=18, transform=_ax.transAxes)\n",
    "\n",
    "## Change positions of axis manually since plt.tight_layout() doesn't work for these figures\n",
    "# Figure (a)\n",
    "pos = ax0.get_position()  # Get the current position of the axis\n",
    "new_pos = [pos.x0, pos.y0, pos.width, pos.height]\n",
    "ax0.set_position(new_pos)\n",
    "# Figure (b)\n",
    "pos = ax1.get_position()  # Get the current position of the axis\n",
    "new_pos = [pos.x0, pos.y0-0.04, pos.width, pos.height]\n",
    "ax1.set_position(new_pos)\n",
    "# Colorbar\n",
    "pos = ax2.get_position()  # Get the current position of the axis\n",
    "new_pos = [pos.x0, pos.y0-0.1, pos.width, pos.height*0.7]\n",
    "ax2.set_position(new_pos)\n",
    "# Text\n",
    "for _ax in [ax3, ax4]:\n",
    "    pos = _ax.get_position()  # Get the current position of the axis\n",
    "    new_pos = [pos.x0, pos.y0-0.094, pos.width, pos.height]\n",
    "    _ax.set_position(new_pos)\n",
    "# Heatmaps\n",
    "for _ax in axs.flatten():\n",
    "    pos = _ax.get_position()  # Get the current position of the axis\n",
    "    new_pos = [pos.x0, pos.y0-0.09, pos.width, pos.height]\n",
    "    _ax.set_position(new_pos)\n",
    "\n",
    "## Annotate (a), (b), (c)\n",
    "ax0.annotate(text=\"(b)\", \n",
    "             xy=(0,0), \n",
    "             xytext=(-75,192), \n",
    "             xycoords='axes points', \n",
    "             color=\"#333\",\n",
    "             fontsize=18,\n",
    "             weight=\"bold\")\n",
    "ax1.annotate(text=\"(c)\", \n",
    "             xy=(0,0), \n",
    "             xytext=(-75,192), \n",
    "             xycoords='axes points', \n",
    "             color=\"#333\",\n",
    "             fontsize=18,\n",
    "             weight=\"bold\")\n",
    "axs[0,0].annotate(text=\"(a)\", \n",
    "                  xy=(0,0), \n",
    "                  xytext=(-75,212), \n",
    "                  xycoords='axes points', \n",
    "                  color=\"#333\",\n",
    "                  fontsize=18,\n",
    "                  weight=\"bold\")\n",
    "\n",
    "# For some reason the subplots move down in the stored figure.\n",
    "# So for the actual figure, we need to shift all ax's up a bit\n",
    "for _ax in [ax2,ax3,ax4]+axs.flatten().tolist():\n",
    "    pos = _ax.get_position()  # Get the current position of the axis\n",
    "    new_pos = [pos.x0, pos.y0+0.13, pos.width, pos.height]\n",
    "    _ax.set_position(new_pos)\n",
    "\n",
    "fig.savefig(\"experimental-results.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heating / Variance appendix figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = get_data_folders(base_dir+\"20241222/\", start=144959, stop=155651)[0::18]\n",
    "delay_times = [300, 350, 400, 450, 500, 550, 650, 750]\n",
    "\n",
    "results_means = np.zeros(len(delay_times))\n",
    "results_stds = np.zeros(len(delay_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data_folder in enumerate(data_folders):\n",
    "    # Get 0 counts\n",
    "    with h5py.File(data_folder+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0_rb = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "    results_means[i]  = np.mean(counts_0_rb, axis=0)\n",
    "    results_stds[i]  = np.std(counts_0_rb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_data[3] = dict(\n",
    "    x0=delay_times,\n",
    "    y0=results_means,\n",
    "    y1=results_stds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folders = [\n",
    "    (\"20241216/\", 124400),\n",
    "    (\"20241216/\", 131943),\n",
    "]\n",
    "\n",
    "data_folders = [get_data_folders(base_dir+x[0], start=x[1], stop=x[1])[0] for x in data_folders]\n",
    "Mmax = 500\n",
    "K = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_errors = np.zeros(len(data_folders))\n",
    "results_stds = np.zeros(len(data_folders))\n",
    "\n",
    "results_mean = np.zeros((10,len(data_folders)))\n",
    "popts = []\n",
    "\n",
    "for i,data_folder in enumerate(data_folders):\n",
    "    weights = np.arange(10)\n",
    "    M_prb = (np.array([sum(weights[:(i+1)])/np.sum(weights) for i in range(10)]) * Mmax).astype(int)\n",
    "    M_prb[0] = 1\n",
    "\n",
    "    # Get 0 counts\n",
    "    with h5py.File(data_folder+\"/dataset.hdf5\", \"r\") as f:\n",
    "        counts_0_prb = np.array(list(f[\"counts_0\"]))\n",
    "\n",
    "    outputs_z = counts_0_prb[0::3].reshape((len(M_prb),K))\n",
    "    outputs_x = counts_0_prb[1::3].reshape((len(M_prb),K))\n",
    "    outputs_y = counts_0_prb[2::3].reshape((len(M_prb),K))\n",
    "\n",
    "    # Convert counts to expectations values\n",
    "    outputs_z = -(2*outputs_z - 1)\n",
    "    outputs_x = -(2*outputs_x - 1)\n",
    "    outputs_y = -(2*outputs_y - 1)\n",
    "\n",
    "    # Get results and average\n",
    "    results_prb = np.sqrt(outputs_z**2 + outputs_x**2 + outputs_y**2)\n",
    "    outputs_mean_prb = np.mean(results_prb, axis=1)\n",
    "    results_mean[:,i] = outputs_mean_prb\n",
    "\n",
    "    # Fit exponential\n",
    "    popt_prb,pcov_prb = curve_fit(fun, M_prb, outputs_mean_prb, p0=[0.25,0.999,0.5])\n",
    "    perr_prb = np.sqrt(np.diag(pcov_prb))\n",
    "    popts.append(popt_prb)\n",
    "\n",
    "    # Extract error\n",
    "    results_errors[i] = (1-popt_prb[1])/2/gates_per_clifford\n",
    "    results_stds[i] = (perr_prb[1])/2/gates_per_clifford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = fig_prepare(r\"Seq. length $M$\", r\"Purity $\\mathcal{P}$\")\n",
    "ax.plot(M_prb, fun(M_prb, *popts[0]), linestyle=\"-\", linewidth=2, color=\"#f1a226\", label=\"With averaging\")\n",
    "ax.plot(M_prb, fun(M_prb, *popts[1]), linestyle=\"-\", linewidth=2, color=\"#298c8c\", label=\"Without averaging\")\n",
    "ax.plot(M_prb, results_mean[:,0], linestyle=\"\", marker=\".\", markersize=9, color=\"#f1a226\")\n",
    "ax.plot(M_prb, results_mean[:,1], linestyle=\"\", marker=\".\", markersize=9, color=\"#298c8c\")\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "ax.annotate(text=r\"$F_{\\text{incoh.}}$ = \"+str(np.round(1-results_errors[0],4)),\n",
    "            xy=(0,1),\n",
    "            xytext=(150,70),\n",
    "            xycoords='figure points',\n",
    "            fontsize=18,\n",
    "            color=\"#f1a226\")\n",
    "ax.annotate(text=r\"$F_{\\text{incoh.}}$ = \"+str(np.round(1-results_errors[1],4)),\n",
    "            xy=(0,1),\n",
    "            xytext=(240,160),\n",
    "            xycoords='figure points',\n",
    "            fontsize=18,\n",
    "            color=\"#298c8c\")\n",
    "\n",
    "fig.legend(loc=[0.45,0.74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only protocol 2 and 3\n",
    "M = figure_data[1][\"x0\"]\n",
    "rb_popts = figure_data[1][\"y0\"][5:15,:]\n",
    "rb_vals = figure_data[1][\"y1\"][5:15,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list1 = [\"#f7d9a2\", \"#f5c26a\", \"#f1a226\", \"#d17e16\", \"#b45b09\"]\n",
    "color_list2 = [\"#a6dede\", \"#63b6b6\", \"#298c8c\", \"#1f6f6f\", \"#155050\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = fig_prepare(r\"Seq. length $M$\", r\"$F_\\text{seq}$ - fitted exponential\")\n",
    "\n",
    "for i in range(4):\n",
    "    ax.plot(M, rb_vals[i,:] - fun(M, *rb_popts[i]), linewidth=2, color=color_list1[i], label=f\"{np.round(tgs[i],1)}ns, P2\")\n",
    "    ax.plot(M, rb_vals[5+i,:] - fun(M, *rb_popts[5+i]), linewidth=2, color=color_list2[i], label=f\"{np.round(tgs[i],1)}ns, P3\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3, 1, figsize=(9,9.2), dpi=300, height_ratios=[0.66,1,0.635])\n",
    "\n",
    "## Plot figure (a)\n",
    "delay_times = figure_data[3][\"x0\"]\n",
    "results_means = figure_data[3][\"y0\"]\n",
    "results_stds = figure_data[3][\"y1\"]\n",
    "(_, caps1, _) = ax[0].errorbar(delay_times, results_means, yerr=results_stds, linestyle=\"\", marker=\".\", markersize=11, capsize=6, linewidth=2, color=colors[\"blue\"])\n",
    "\n",
    "ax[0].set_xlabel(r\"Delay time ($\\mu$s)\")\n",
    "ax[0].set_ylabel(r\"$F_\\text{seq}(M=750)$\")\n",
    "\n",
    "## Plot figure (b)\n",
    "for i in range(4):\n",
    "    ax[1].plot(M, rb_vals[i,:] - fun(M, *rb_popts[i]), linewidth=2, color=color_list1[i], label=f\"P2, {np.round(tgs[i+1],1)}ns\")\n",
    "for i in range(4):\n",
    "    ax[1].plot(M, rb_vals[5+i,:] - fun(M, *rb_popts[5+i]), linewidth=2, color=color_list2[i], label=f\"P3, {np.round(tgs[i+1],1)}ns\")\n",
    "\n",
    "# ax[1].legend(loc=[0.45,0.03], ncols=2, columnspacing=0.9)\n",
    "ax[1].legend(loc=[0.185,0.61], ncols=3, columnspacing=0.9, frameon=False)\n",
    "\n",
    "ax[1].set_xlabel(r\"Seq. length $M$\")\n",
    "ax[1].set_ylabel(r\"$F_\\text{seq}$ - fitted exponential\")\n",
    "ax[1].set_ylim(-0.02,0.02)\n",
    "\n",
    "## Plot figure (c)\n",
    "ax[2].plot(M_prb, fun(M_prb, *popts[0]), linestyle=\"-\", linewidth=2, color=\"#f1a226\", label=\"With averaging\")\n",
    "ax[2].plot(M_prb, fun(M_prb, *popts[1]), linestyle=\"-\", linewidth=2, color=\"#298c8c\", label=\"Without averaging\")\n",
    "ax[2].plot(M_prb, results_mean[:,0], linestyle=\"\", marker=\".\", markersize=11, color=color_list1[-2])\n",
    "ax[2].plot(M_prb, results_mean[:,1], linestyle=\"\", marker=\".\", markersize=11, color=color_list2[-2])\n",
    "ax[2].set_ylim(0,1)\n",
    "ax[2].set_xlabel(r\"Seq. length $M$\")\n",
    "ax[2].set_ylabel(r\"Purity $\\mathcal{P}$\")\n",
    "ax[2].legend(loc=[0.6,0.54], frameon=False)\n",
    "\n",
    "# Add 'a' and 'b' labels\n",
    "ax[0].annotate(text=\"(a)\", \n",
    "               xy=(0,1), \n",
    "               xytext=(95,601.5), \n",
    "               xycoords='figure points', \n",
    "               fontsize=18,\n",
    "               weight=\"bold\")\n",
    "ax[1].annotate(text=\"(b)\", \n",
    "               xy=(0,1), \n",
    "               xytext=(95,412), \n",
    "               xycoords='figure points', \n",
    "               fontsize=18,\n",
    "               weight=\"bold\")\n",
    "ax[2].annotate(text=\"(c)\", \n",
    "               xy=(0,1), \n",
    "               xytext=(95,160), \n",
    "               xycoords='figure points', \n",
    "               fontsize=18,\n",
    "               weight=\"bold\")\n",
    "\n",
    "ax[1].set_xlim(0,2000)\n",
    "ax[1].set_xticks([0,500,1000,1500,2000])\n",
    "ax[2].set_xlim(0,500)\n",
    "# ax[2].set_xticks([0])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"rb-experiment-appendix.png\", dpi=200)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
